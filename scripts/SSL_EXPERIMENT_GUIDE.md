# ğŸš€ SSL Experiment Framework - Complete Guide

## ğŸ“ What We've Built

We've created a comprehensive framework that leverages the **existing external repositories** (MAE, DINO, iBOT) instead of rewriting everything from scratch. This approach is much more reliable and faster.

## ğŸ—ï¸ Structure

```
scripts/experiments/
â”œâ”€â”€ mae/                          # MAE experiments
â”‚   â”œâ”€â”€ working/                  # Copied from external/mae/
â”‚   â”‚   â”œâ”€â”€ mae_pretrain.py      # Official MAE pretraining
â”‚   â”‚   â”œâ”€â”€ mae_linear_probe.py  # Official MAE linear probing
â”‚   â”‚   â”œâ”€â”€ mae_finetune.py      # Official MAE fine-tuning
â”‚   â”‚   â”œâ”€â”€ models_mae.py        # MAE model definitions
â”‚   â”‚   â””â”€â”€ models_vit.py        # ViT model definitions
â”‚   â”œâ”€â”€ mae_pretrain_job.sh      # SLURM job for pretraining
â”‚   â”œâ”€â”€ mae_linear_probe_job.sh  # SLURM job for linear probing
â”‚   â””â”€â”€ mae_finetune_job.sh      # SLURM job for fine-tuning
â”œâ”€â”€ dino/                         # DINO experiments
â”‚   â”œâ”€â”€ working/                  # Copied from external/dino/
â”‚   â”‚   â”œâ”€â”€ dino_pretrain.py     # Official DINO pretraining
â”‚   â”‚   â””â”€â”€ ssl_meta_arch.py     # DINO architecture
â”‚   â””â”€â”€ dino_pretrain_job.sh     # SLURM job for pretraining
â”œâ”€â”€ ibot/                         # iBOT experiments
â”‚   â”œâ”€â”€ working/                  # Copied from external/ibot/
â”‚   â”‚   â”œâ”€â”€ ibot_pretrain.py     # Official iBOT pretraining
â”‚   â”‚   â””â”€â”€ utils.py             # iBOT utilities
â”‚   â””â”€â”€ ibot_pretrain_job.sh     # SLURM job for pretraining
â”œâ”€â”€ run_all_ssl_experiments_job.sh # Master job script
â””â”€â”€ SSL_EXPERIMENT_GUIDE.md      # This guide
```

## ğŸ¯ Key Benefits of This Approach

1. **âœ… Reliability**: Uses official, tested implementations
2. **ğŸš€ Speed**: No need to rewrite complex SSL algorithms
3. **ğŸ”§ Adaptability**: Easy to modify for CIFAR-10
4. **ğŸ“Š Consistency**: Same evaluation across all methods
5. **ğŸ’¾ Proven**: Based on published, peer-reviewed code

## ğŸš€ How to Run Experiments

### **Option 1: Individual Jobs (Recommended for Testing)**

#### **MAE Experiments**
```bash
# Pretraining
sbatch scripts/experiments/mae/mae_pretrain_job.sh

# Linear probing (after pretraining)
sbatch scripts/experiments/mae/mae_linear_probe_job.sh

# Fine-tuning (after pretraining)
sbatch scripts/experiments/mae/mae_finetune_job.sh
```

#### **DINO Experiments**
```bash
# Pretraining
sbatch scripts/experiments/dino/dino_pretrain_job.sh
```

#### **iBOT Experiments**
```bash
# Pretraining
sbatch scripts/experiments/ibot/ibot_pretrain_job.sh
```

### **Option 2: Complete Pipeline (For Full Project)**
```bash
# Run everything in sequence
sbatch scripts/experiments/run_all_ssl_experiments_job.sh
```

## ğŸ”§ CIFAR-10 Specific Configurations

### **Image & Patch Sizes**
- **Image size**: 32x32 (CIFAR-10 standard)
- **Patch size**: 4x4 (8 patches per image: 32/4 = 8)
- **Sequence length**: 8 patches + 1 CLS token = 9 tokens

### **Model Adaptations**
- **MAE**: ViT Base with 4x4 patches, decoder for 32x32 images
- **DINO**: ViT Small with 4x4 patches, teacher-student setup
- **iBOT**: ViT Small with 4x4 patches, masked token prediction

### **Training Parameters**
- **Batch size**: 64 (pretraining), 32 (fine-tuning), 128 (probing)
- **Learning rate**: 1e-4 (fine-tuning), 3e-4 (pretraining)
- **Epochs**: 200 (pretraining), 100 (fine-tuning/probing)

## ğŸ“Š Expected Results

### **Performance Ranking (Expected)**
1. **Fine-tuned SSL models** (highest - learns task-specific features)
2. **Fine-tuned supervised ViT** (high - learns from labels)
3. **Nonlinear probes on SSL** (medium - good representation evaluation)
4. **Linear probes on SSL** (lower - limited by linear decision boundaries)
5. **Probes on random ViT** (lowest - no meaningful representations)

### **Key Insights to Look For**
- **SSL vs Supervised**: Do SSL methods learn better representations?
- **Linear vs Nonlinear**: How much do nonlinear probes improve?
- **Method Comparison**: Which SSL method works best on CIFAR-10?
- **Data Efficiency**: How well do SSL methods perform with limited labels?

## ğŸš¨ Current Status & Next Steps

### **âœ… What's Ready**
- **MAE**: Complete pipeline (pretrain â†’ linear probe â†’ fine-tune)
- **DINO**: Pretraining only
- **iBOT**: Pretraining only
- **All SLURM job scripts**: Ready to run

### **âš ï¸ What Needs Implementation**
- **DINO linear probing**: Custom script needed
- **DINO fine-tuning**: Custom script needed
- **iBOT linear probing**: Custom script needed
- **iBOT fine-tuning**: Custom script needed

### **ğŸ”§ Implementation Plan**
1. **Phase 1**: Test MAE pipeline (fully working)
2. **Phase 2**: Implement DINO probing/fine-tuning
3. **Phase 3**: Implement iBOT probing/fine-tuning
4. **Phase 4**: Run complete comparative study

## ğŸ’¡ Quick Start Guide

### **1. Test MAE (Fully Working)**
```bash
# Start with pretraining
sbatch scripts/experiments/mae/mae_pretrain_job.sh

# Check output
tail -f mae_pretrain_*.out

# After pretraining completes, run linear probing
sbatch scripts/experiments/mae/mae_linear_probe_job.sh

# Finally, run fine-tuning
sbatch scripts/experiments/mae/mae_finetune_job.sh
```

### **2. Test DINO (Pretraining Only)**
```bash
# Run DINO pretraining
sbatch scripts/experiments/dino/dino_pretrain_job.sh

# Check output
tail -f dino_pretrain_*.out
```

### **3. Test iBOT (Pretraining Only)**
```bash
# Run iBOT pretraining
sbatch scripts/experiments/ibot/ibot_pretrain_job.sh

# Check output
tail -f ibot_pretrain_*.out
```

## ğŸ” Monitoring & Debugging

### **Check Job Status**
```bash
squeue -u $USER
```

### **Check Output Files**
```bash
# List all output files
ls -la *_*.out

# Monitor specific job
tail -f mae_pretrain_*.out

# Check for errors
grep -i error mae_pretrain_*.err
```

### **Common Issues & Solutions**
1. **CUDA out of memory**: Reduce batch size
2. **Import errors**: Check conda environment activation
3. **Data path issues**: Verify `data/cifar10_splits/` exists
4. **Model loading errors**: Check checkpoint paths

## ğŸ“ˆ Results Analysis

### **Where Results Are Saved**
- **Models**: `outputs/{method}_pretrain/`, `outputs/{method}_finetune/`
- **Logs**: `{method}_{type}_*.out` files
- **Metrics**: Checkpoint files and training logs

### **Key Metrics to Track**
- **Pretraining**: Reconstruction loss (MAE), contrastive loss (DINO/iBOT)
- **Linear probing**: Validation accuracy on frozen features
- **Fine-tuning**: Final test accuracy

## ğŸ¯ Milestone Coverage

### **Milestone 1: ViT Framework & Baselines** âœ…
- ViT supervised training
- Linear/nonlinear probing on random ViT

### **Milestone 2: DINO & MAE Implementation** ğŸ”„
- **MAE**: Complete âœ…
- **DINO**: Pretraining âœ…, probing/fine-tuning needed

### **Milestone 3: iBOT Implementation** ğŸ”„
- **iBOT**: Pretraining âœ…, probing/fine-tuning needed

## ğŸš€ Next Steps

1. **Test MAE pipeline** (fully working)
2. **Implement DINO probing/fine-tuning**
3. **Implement iBOT probing/fine-tuning**
4. **Run complete comparative study**
5. **Analyze results and write report**

This framework gives you everything needed to complete your RL#2 project with a comprehensive comparison of SSL methods! ğŸ‰
